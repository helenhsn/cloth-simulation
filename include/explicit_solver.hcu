#ifndef EXPLICIT_SOLVER_H
#define EXPLICIT_SOLVER_H

#include "mesh.hcu"
#include "solver.h"
#include "cuda_utils.hcu"

using namespace std;



__device__ void atomicadd(glm::vec3 *tab, int idx, glm::vec3 val, int seed)
{
    int offset1 = seed % 3;
    int offset2 = (seed + 1) % 3;
    int offset3 = (seed + 2) % 3;
    atomicAdd(&(tab[idx].x) + offset1, val[offset1]);
    atomicAdd(&(tab[idx].x) + offset2, val[offset2]);
    atomicAdd(&(tab[idx].x) + offset3, val[offset3]);
}

__device__ glm::vec3 computeSpringForces(bool isStretchSpring, bool isAFixed, bool isBFixed, int i, int j, glm::vec3 x_i, glm::vec3 v_i, glm::vec3 x_j, glm::vec3 v_j, float L, float Ks, float Kd)
{
    glm::vec3 diff_xij = x_j - x_i;
    float length_xij  = sqrt(dot(diff_xij, diff_xij));

    if (abs(length_xij) < 10e-3) return glm::vec3(0.0f);
    glm::vec3 dir_xij = diff_xij/length_xij;

    float spring = Ks*(length_xij - L);
    float damping = Kd*dot(v_j-v_i, dir_xij);

    // printf("\n\n nÂ°%i : SPRING = %f // DAMPING = %f  ", i, spring, damping);
    float correction = 0.0;
    float tau_c = 0.1;
    float shrinking = (length_xij - L)/L;
    if (shrinking > tau_c)
    {
        correction = 3.0*Ks*(length_xij - (1.0-tau_c) * L);
        // if first point && second point are not fixed
        if (!isAFixed && !isBFixed) 
        {
            correction *= 0.5;
        }

    }
    glm::vec3 total = (spring + damping + correction)*dir_xij;

    // if (isnan(spring)) printf("\nvi = %f %f %f vj = %f %f %f Kd = %f", v_i.x, v_i.y, v_i.z, v_j.x, v_j.y, v_j.z, Kd);

    // if (isnan(total.x)) printf("\nspring = %f // damping = %f // correction = %f \n >>> other debug : diff_xij = %f %f %f // ", spring, damping, correction, dir_xij.x, dir_xij.y, dir_xij.z);
    return total;
}


__global__ void updateInternalForces(bool isStretchSpring, int maxTid, int Ngrid, int N, glm::ivec2 *springIds, glm::vec3 *xIter, glm::vec3 *vIter, glm::vec3 *FIter, float L, float Ks, float Kd)
{
    int j = threadIdx.x + blockIdx.x*blockDim.x;
    int i = threadIdx.y + blockIdx.y*blockDim.y;
    int tid = j*N+i;

    if (tid < maxTid )
    {
        glm::ivec2 ids = springIds[tid];
        bool isAFixed = (ids.x % Ngrid == 0);
        bool isBFixed = (ids.y % Ngrid == 0);
        glm::vec3 fSpring = computeSpringForces(isStretchSpring, isAFixed, isBFixed, ids.x, ids.y, xIter[ids.x], vIter[ids.x], xIter[ids.y], vIter[ids.y], L, Ks, Kd);

        float *addA = &FIter[ids.x].x;
        float *addB = &FIter[ids.y].x;

        atomicAdd(addA, fSpring.x);
        atomicAdd(addA + 1, fSpring.y);
        atomicAdd(addA + 2, fSpring.z);

        atomicAdd(addB, -fSpring.x);
        atomicAdd(addB + 1, -fSpring.y);
        atomicAdd(addB + 2, -fSpring.z);

        if (ids.y==33 && ids.x ==0) printf("\n tidI = %i // tidJ = %i // F = %f %f %f, xi=%f %f %f // xj =%f %f %f", i, j, -fSpring.x, -fSpring.y, -fSpring.z, xIter[ids.x].x, xIter[ids.x].y, xIter[ids.x].z, xIter[ids.y].x, xIter[ids.y].y, xIter[ids.y].z);

        // if (ids.x == 6452) printf("\nok : test = %f // fspring = %f %f %f", FIter[ids.x].x, fSpring.x, fSpring.y, fSpring.z);
        // if (ids.y == 6452) printf("\nok : test = %f // fspring = %f %f %f", FIter[ids.y].x, fSpring.x, fSpring.y, fSpring.z);
        

    }



}

__global__ void updateIterBuffers(int maxTid, int N, float kOffset, float yOffset, glm::vec3 *x, glm::vec3 *v, glm::vec3 *xIter, glm::vec3 *vIter, glm::vec3 *FIter, glm::vec3 *vIterAcc, float m)
{
    /**
     * Initializes the 2 buffers used for computing RK4 iterations 
    */

    // TODO use shared mem
    int j = threadIdx.x + blockIdx.x*blockDim.x;
    int i = threadIdx.y + blockIdx.y*blockDim.y;

    int tid = j*N+i;

    if (tid < maxTid)
    {

        float fixedFactor = 0.0;
        if (true)
        {
            fixedFactor = 1.0;
        }
        xIter[tid] = x[tid] + fixedFactor * yOffset * vIter[tid]; // offset x
        vIter[tid] = v[tid] + fixedFactor * yOffset * FIter[tid]/m; // xDot1,2,3,4

        vIterAcc[tid] += kOffset * vIter[tid];
        FIter[tid] = glm::vec3(0.0);
    }

}

__device__ glm::vec3 computeNormal(int tid, int i, int j, int N_m1, int N, glm::vec3 *x)
{
    glm::vec3 shear_vec1 = j == N_m1? x[tid] - x[tid-N] : x[tid+N] - x[tid]; // right vec
    glm::vec3 shear_vec2 = i == 0? x[tid] - x[tid+1] : x[tid-1] - x[tid]; // up vec

    glm::vec3 normal1 = normalize(cross(shear_vec1, shear_vec2));

    glm::vec3 shear_vec3 = j == 0 ? x[tid] - x[tid+N] : x[tid - N] - x[tid]; // left vec
    glm::vec3 shear_vec4 = i == N_m1 ?  x[tid] - x[tid-1] : x[tid+1] - x[tid]; // bottom vec

    glm::vec3 normal2 = normalize(cross(shear_vec3, shear_vec4));

    return normalize(0.5f*(normal1+normal2));
}

__global__ void updateExternalForces(int maxTid, int N, float kOffset, glm::vec3 *xIter, glm::vec3 *vIter, glm::vec3 *FIter, glm::vec3 *FIterAcc, glm::vec3 *n, float m, glm::vec3 absWind, glm::vec3 normWind, glm::vec3 gravity, float Ka)
{
    int j = threadIdx.x + blockIdx.x*blockDim.x;
    int i = threadIdx.y + blockIdx.y*blockDim.y;

    int tid = j*N+i;

    if (tid < maxTid)
    {
        int N_m1 = N-1;

        glm::vec3 normal = computeNormal(tid, i, j, N_m1, N, xIter);

        n[tid] = normal;


        FIter[tid] += dot(abs(normal), absWind) * normWind + gravity - Ka*vIter[tid]; // TODO add all external forces : wind force + gravity force + friction force

        FIterAcc[tid] += kOffset * FIter[tid];
        // if (tid == 6452) printf("\nFiter = %f %f %f", FIter[tid].x, FIter[tid].y, FIter[tid].z);
    }
}

__global__ void updateScheme(int maxTid, int N, glm::vec3 *x, glm::vec3 *v, glm::vec3 *vIterAcc, glm::vec3 *FIterAcc, glm::vec3 *collisionsFBuffer, float h, float m, bool *updatePt)
{
    int j = threadIdx.x + blockIdx.x*blockDim.x;
    int i = threadIdx.y + blockIdx.y*blockDim.y;

    int tid = j*N+i;

    if (tid < maxTid)
    {

        if (true)
        {
            // RK4 scheme
            // if (isnan(v[tid].x)) printf("\nNAN VEL // TID = %i // v = %f %f %f // F = %f %f %f // C = %f %f %f", tid, v[tid].x, v[tid].y, v[tid].z, FIterAcc[tid].x, FIterAcc[tid].y, FIterAcc[tid].z, collisionsFBuffer[tid].z, collisionsFBuffer[tid].y, collisionsFBuffer[tid].z);
            // if (isnan(x[tid].x)) printf("\nNAN POS // TID = %i // v = %f %f %f // F = %f %f %f // C = %f %f %f", tid, v[tid].x, v[tid].y, v[tid].z, FIterAcc[tid].x, FIterAcc[tid].y, FIterAcc[tid].z, collisionsFBuffer[tid].z, collisionsFBuffer[tid].y, collisionsFBuffer[tid].z);
            x[tid] = x[tid] + h*vIterAcc[tid]/6.0f;
            v[tid] += h*(FIterAcc[tid] + collisionsFBuffer[tid])/(6.0f*m);


        }


        if (tid == 33) printf("\nF = %f %f %f // collisions = %f %f %f", FIterAcc[tid].x, FIterAcc[tid].y, FIterAcc[tid].z, collisionsFBuffer[tid].x, collisionsFBuffer[tid].y, collisionsFBuffer[tid].z);
        vIterAcc[tid] = glm::vec3(0.0f);
        collisionsFBuffer[tid] = FIterAcc[tid];
        FIterAcc[tid] = glm::vec3(0.0f);

    }

}



__global__ void initScheme(int maxTid, glm::vec3 *v, glm::vec3 *xIter, glm::vec3 *vIter, glm::vec3 *FIter, glm::vec3 *vIterAcc, glm::vec3 *FIterAcc, bool *updatePt, int N)
{
    int j = threadIdx.x + blockIdx.x*blockDim.x;
    int i = threadIdx.y + blockIdx.y*blockDim.y;

    int tid = j*N+i;

    if (tid < maxTid)
    {       
        v[tid] = glm::vec3(0.0);
        FIter[tid] = glm::vec3(0.0);
        vIterAcc[tid] = glm::vec3(0.0);
        vIter[tid] = glm::vec3(0.0);
        xIter[tid] = glm::vec3(0.0);
        FIterAcc[tid] = glm::vec3(0.0);
        updatePt[tid] = true;

    }
}

struct SpringData
{
    std::vector<glm::ivec2> indices;
    
    // Cuda calls var
    glm::ivec2 *indicesCudaPtr;
    int sqrtN;
    dim3 gridSize;

    float restLength;
};

class ExplicitSolver: public Solver
{
    private:

    float m_Ks;
    float m_Kd;
    float m_unitM;
    glm::vec3 m_wind;
    glm::vec3 m_windNormed;
    glm::vec3 m_gravity;
    float *m_windUI;
    float m_Ka;
    bool m_correctSpring[4];

    int m_sqrtNRound;

    // data structures
    SpringData *m_springs;
    dim3 m_gridSizeScheme;
    dim3 m_blockSize;

    // RK4 buffers
    glm::vec3 *m_V; // current velocity for each particle
    glm::vec3 *m_xIter;
    glm::vec3 *m_vIter;
    glm::vec3 *m_vIterAcc;
    glm::vec3 *m_FIter; // sum of forces for each particle
    glm::vec3 *m_FIterAcc;

    ExplicitSolver(const ExplicitSolver &other);
    ExplicitSolver& operator=(const ExplicitSolver &other);

    void initSprings(const int &N, const float &L)
    {
        int N_minus_1 = N-1;
        int N_minus_2 = N-2;

        m_springs = new SpringData[4];
        float stretch_L(sqrt(2.0*L*L));
        float bend_L(2.0*L);
        float bendDiag_L(2.0*stretch_L);
        float restLengths[4] = {L, stretch_L, bend_L, bendDiag_L};

        // filling the data structure going from squares of length=2
        for (int j = 0; j <N; ++j)
        {
            for (int i = 0; i<N; ++i)
            {
                int id = j*N+i;

                // add structural springs id & length
                if (j < N_minus_1) m_springs[0].indices.push_back(glm::ivec2(id, id+N)); // right spring
                if (i < N_minus_1) m_springs[0].indices.push_back(glm::ivec2(id, id+1)); // bottom spring


                // add stretch springs id & length
                if (i < N_minus_1 && j < N_minus_1) m_springs[1].indices.push_back(glm::ivec2(id, id+N+1)); // 1st diag spring
                if (i > 0 && j < N_minus_1) m_springs[1].indices.push_back(glm::ivec2(id, id+N-1)); // 2nd diag spring

                // adding bend springs
                if (j < N_minus_2) m_springs[2].indices.push_back(glm::ivec2(id, id+2*N)); // right bend spring
                if (i < N_minus_2) m_springs[2].indices.push_back(glm::ivec2(id, id+2)); // bottom bend spring

                if (i < N_minus_2 && j < N_minus_2) m_springs[3].indices.push_back(glm::ivec2(id, id + 2*N + 2)); // 1st diag bend spring
                if (i > 1 && j < N_minus_2) m_springs[3].indices.push_back(glm::ivec2(id, id+2*N-2)); // 2nd diag bend spring

            }
        }

        for (int i=0; i<4; ++i)
        {   
            SpringData *spring = &m_springs[i];
            cudaErrorCheck(cudaMalloc((void **) &spring->indicesCudaPtr, sizeof(glm::ivec2)*spring->indices.size()));
            cudaErrorCheck(cudaMemcpy(spring->indicesCudaPtr, spring->indices.data(), sizeof(glm::ivec2)*spring->indices.size(), cudaMemcpyHostToDevice));
            m_springs[i].sqrtN = int(ceil(sqrt(spring->indices.size())));
            m_springs[i].restLength = restLengths[i];
            m_springs[i].gridSize = dim3((m_springs[i].sqrtN + 31)/32, (m_springs[i].sqrtN + 31)/32, 1);
        } 
    }

    void updateSpringForces(Plane *grid)
    {
        for (int i=0; i<4; ++i)
        {
            SpringData spring = m_springs[i];
            updateInternalForces<<<spring.gridSize, m_blockSize>>>(
                m_correctSpring[i], 
                spring.indices.size(),  
                grid->N(), 
                spring.sqrtN, 
                spring.indicesCudaPtr, 
                m_xIter, 
                m_vIter, 
                m_FIter, 
                spring.restLength, 
                m_Ks, 
                m_Kd
            );

        }
        
        cudaErrorCheck(cudaDeviceSynchronize());
        
    }

    void updateRK4(Plane *grid, float kOffset, float yOffset)
    {
        
        // INIT SUB ITERATION BUFFERS FOR POSITION AND VELOCITY (y = y + yOffset * k)

        updateIterBuffers<<<m_gridSizeScheme, m_blockSize>>>(
            grid->getVerticesNb(), 
            grid->N(), 
            kOffset, 
            yOffset, 
            (glm::vec3 *) grid->getDataPtr(0), 
            m_V, 
            m_xIter, 
            m_vIter, 
            m_FIter, 
            m_vIterAcc, 
            m_unitM
            );

        cudaErrorCheck(cudaDeviceSynchronize());

        updateSpringForces(grid);

        updateExternalForces<<<m_gridSizeScheme, m_blockSize>>>(
            grid->getVerticesNb(), 
            grid->N(),
            kOffset, 
            m_xIter, 
            m_vIter, 
            m_FIter, 
            m_FIterAcc, 
            (glm::vec3 *) grid->getDataPtr(1), 
            m_unitM, 
            m_wind, 
            m_windNormed, 
            m_gravity, 
            m_Ka 
            );
        cudaErrorCheck(cudaDeviceSynchronize());
    }

    void runRK4Iterations(Plane *grid)
    {
        // compute k1, k2, k3 and k4 iterations of RK4 algorithm
        updateRK4(grid, 1.0, 0.0);
        updateRK4(grid, 2.0, m_timeStep*0.5);
        updateRK4(grid, 2.0, m_timeStep*0.5);
        updateRK4(grid, 1.0, m_timeStep);

    }


    public:

    ~ExplicitSolver()
    {
        cudaFree(m_xIter);
        cudaFree(m_vIter);
        cudaFree(m_vIterAcc);
        cudaFree(m_FIter);
        cudaFree(m_FIterAcc);
        cudaFree(m_V);
        for (int i=0; i<4; ++i)
        {
            cudaFree(m_springs[i].indicesCudaPtr);
        };
        delete m_springs;
    };

    float *Ks() {return &m_Ks;};
    float *Kd() {return &m_Kd;};
    float *Ka() {return &m_Ka;};
    float *m() {return &m_unitM;};
    float *L() {return &m_springs[0].restLength;};
    float *wind() 
    {
        for (int i = 0; i<3; ++i)
            m_windUI[i] = m_wind[i];
        return m_windUI;
    };

    glm::vec3 *getFBuffer() {return m_FIterAcc;};
    

    ExplicitSolver(
        Plane *grid, 
        bool *updatePt
    ) : 
    Solver(0.0012f),
    m_Ks(230.0), 
    m_Kd(10.0), 
    m_Ka(0.1), 
    m_unitM(0.20), 
    m_wind(glm::vec3(0.0f)),
    m_gravity(glm::vec3(0.0f, -9.81f*m_unitM, 0.0f)),
    m_correctSpring({false, true, false, false})
    {
        m_windUI = new float[3]; 
        wind();
        
        std::cout << "N = " << grid->N() << " && NB DE PTS :" << grid->getVerticesNb() << std::endl << std::flush ;
        
        // solver's buffers allocation
        cudaErrorCheck(cudaMalloc((void **) &m_V, sizeof(glm::vec3)*grid->getVerticesNb()));
        cudaErrorCheck(cudaMalloc((void **) &m_xIter, sizeof(glm::vec3)*grid->getVerticesNb()));
        cudaErrorCheck(cudaMalloc((void **) &m_vIter, sizeof(glm::vec3)*grid->getVerticesNb()));
        cudaErrorCheck(cudaMalloc((void **) &m_FIter, sizeof(glm::vec3)*grid->getVerticesNb()));
        cudaErrorCheck(cudaMalloc((void **) &m_vIterAcc, sizeof(glm::vec3)*grid->getVerticesNb()));
        cudaErrorCheck(cudaMalloc((void **) &m_FIterAcc, sizeof(glm::vec3)*grid->getVerticesNb()));
        
        m_gridSizeScheme = dim3((grid->N()+31)/32, (grid->N()+31)/32, 1);
        m_blockSize = dim3(32, 32, 1);

        // run cuda kernel
        resetScheme(grid, updatePt);

        // init spring data structure
        initSprings(grid->N(), grid->L());
    };  

    void resetScheme(Plane *grid, bool *updatePt)
    {
        initScheme<<<m_gridSizeScheme, m_blockSize>>>(
            grid->getVerticesNb(), 
            m_V, 
            m_xIter, 
            m_vIter, 
            m_FIter, 
            m_vIterAcc, 
            m_FIterAcc, 
            updatePt,
            grid->N()
            );
        cudaErrorCheck(cudaDeviceSynchronize());
    }

    void step(Plane *grid, bool *updatePt, glm::vec3 *collisionsFBuffer)
    {

        runRK4Iterations(grid);

        updateScheme<<<m_gridSizeScheme, m_blockSize>>>(
            grid->getVerticesNb(), 
            grid->N(),
            (glm::vec3 *) grid->getDataPtr(0), 
            m_V,
            m_vIterAcc, 
            m_FIterAcc, 
            collisionsFBuffer,
            m_timeStep, 
            m_unitM,
            updatePt
            );
        cudaErrorCheck(cudaDeviceSynchronize());

    };

    void updateWind()
    {
        for (int i = 0; i<3; ++i)
            m_wind[i] = m_windUI[i];
        m_windNormed = normalize(m_wind);
        m_wind = abs(m_wind);
    }

    void updateGravity()
    {
        m_gravity.y = -9.81*m_unitM;
    }

    glm::vec3 *getVelocities() {return m_V;};
};

#endif